{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJfEuNdxt1BB"
      },
      "source": [
        "# **AI MOCK INTERVIEW BOT**\n",
        "\n",
        "![](https://theblue.ai/wp-content/uploads/2024/06/LLM-Agent-AI-Agent-LLM-Banner-1024x576.png)\n",
        "\n",
        "\n",
        "## Interactive AI chatbot for job interview preparation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28HOdv_nyTPE"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In today’s competitive job market, effective interview preparation is crucial for career success. Traditional methods often lack personalized feedback, making it hard for candidates to improve.\n",
        "\n",
        "To solve this, we developed an AI Mock Interview Bot. An interactive chatbot that helps users practice job interviews anytime, anywhere. Using advanced natural language processing, it asks both technical and behavioral questions, evaluates answers by comparing them with ideal responses, and provides immediate feedback on content and grammar.\n",
        "\n",
        "This tool boosts confidence and communication skills by highlighting areas for improvement. Our project showcases how AI and NLP can make interview preparation more accessible, personalized, and effective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAMZhQtfyyru"
      },
      "source": [
        "# Data Description\n",
        "#### **All the features in the dataset are described as follows:**\n",
        "\n",
        "\n",
        "\n",
        "* ####  `question` : The interview question asked by the AI bot. This includes technical, behavioral, and general questions commonly asked in job interviews.\n",
        "\n",
        "\n",
        "* #### `ideal_answer` : The recommended or model answer to the question, used to compare and evaluate the users response based on meaning and correctness.\n",
        "\n",
        "\n",
        "\n",
        "####This dataset serves as the foundation for the AI Mock Interview Bot to generate questions and assess answers effectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EmLlM8R0Zqo"
      },
      "source": [
        "# Project Outline\n",
        "###**Steps that we follow:**\n",
        "\n",
        "-  Installing and importing all the required libraries.\n",
        "-  Loading the dataset.\n",
        "-  Exploratory Data Analysis.\n",
        "- Feature Engineering.\n",
        "- Prepare the Dataset for  AI Evaluation.\n",
        "- Implemented Baseline Scoring Model.\n",
        "- Trained and Evaluated the AI Scoring Logic.\n",
        "- Hyperparameter Tuning.\n",
        "- Final Version of AI Interview Bot.\n",
        "- Summary\n",
        "- Future Work ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SodBDvxT8b9c"
      },
      "source": [
        "# Installing and Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers textblob\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsDL7Wiie5gE",
        "outputId": "cdafa857-b2df-4fc2-8bfb-2540c491193d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "rXzT-z70kmj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu-z6gWu8rRF"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import random\n",
        "from textblob import TextBlob\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv0Rn4iy-Lxx"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCNDajV1-XON"
      },
      "source": [
        "#### In this project, the dataset was prepared manually and saved as a CSV file named interview_questions.csv. It contains a collection of commonly asked interview questions along with ideal answers.\n",
        "\n",
        "####We load the dataset directly using **pandas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MMayrShX-fAV",
        "outputId": "bedde169-763a-4328-c185-8075f1fe37f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57,\n        \"samples\": [\n          \"Tell me about yourself.\",\n          \"What is Python?\",\n          \"What is the difference between structured and unstructured data?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ideal_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Talk about education, projects, goals.\",\n          \"Python is a high-level, interpreted programming language known for its simplicity.\",\n          \"A system to manage changes to source code over time.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d820b362-48df-44fb-aaf3-d3c269aea44f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ideal_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tell me about yourself.</td>\n",
              "      <td>Talk about education, projects, goals.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are your strengths?</td>\n",
              "      <td>Mention qualities like leadership, communication.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why should we hire you?</td>\n",
              "      <td>Talk about skills, motivation, and company fit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Describe a challenging project you worked on.</td>\n",
              "      <td>Explain the project and how you handled challe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are your career goals?</td>\n",
              "      <td>Mention short-term and long-term aspirations.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d820b362-48df-44fb-aaf3-d3c269aea44f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d820b362-48df-44fb-aaf3-d3c269aea44f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d820b362-48df-44fb-aaf3-d3c269aea44f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ceec3d8a-5c34-4254-bc96-c599197b6ade\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ceec3d8a-5c34-4254-bc96-c599197b6ade')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ceec3d8a-5c34-4254-bc96-c599197b6ade button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                        question  \\\n",
              "0                        Tell me about yourself.   \n",
              "1                       What are your strengths?   \n",
              "2                        Why should we hire you?   \n",
              "3  Describe a challenging project you worked on.   \n",
              "4                    What are your career goals?   \n",
              "\n",
              "                                        ideal_answer  \n",
              "0             Talk about education, projects, goals.  \n",
              "1  Mention qualities like leadership, communication.  \n",
              "2    Talk about skills, motivation, and company fit.  \n",
              "3  Explain the project and how you handled challe...  \n",
              "4      Mention short-term and long-term aspirations.  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"interview_questions.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhvXns5UBMvf"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "####The dataset `interview_questions.csv` contains interview questions and their corresponding ideal answers. We load the data into a dataframe to understand its structure and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwLogD2WXtb",
        "outputId": "48a112ae-11e0-4090-ad04-4846117ba111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60 entries, 0 to 59\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   question      60 non-null     object\n",
            " 1   ideal_answer  60 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.1+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"interview_questions.csv\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayWDmQcwBuGW",
        "outputId": "a7e68760-b662-46f9-eb82-86a225c75514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        question  \\\n",
            "0                        Tell me about yourself.   \n",
            "1                       What are your strengths?   \n",
            "2                        Why should we hire you?   \n",
            "3  Describe a challenging project you worked on.   \n",
            "4                    What are your career goals?   \n",
            "\n",
            "                                        ideal_answer  \n",
            "0             Talk about education, projects, goals.  \n",
            "1  Mention qualities like leadership, communication.  \n",
            "2    Talk about skills, motivation, and company fit.  \n",
            "3  Explain the project and how you handled challe...  \n",
            "4      Mention short-term and long-term aspirations.  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"interview_questions.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L21QzdKQC1Ic"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "In this project, the key focus is to evaluate user answers against ideal answers using semantic similarity and grammar correctness. The main features we create or extract include:\n",
        "\n",
        "\n",
        "* **Sentence Embeddings :**  Using the SentenceTransformer model (all-MiniLM-L6-v2), we convert both the user’s answer and the ideal answer into numerical vector representations (embeddings). These embeddings capture the semantic meaning of the sentences, enabling us to compare their similarity.\n",
        "\n",
        "* **Semantic Similarity Score :**  We calculate the cosine similarity between the user answer embedding and the ideal answer embedding. This score reflects how close the user’s response is in meaning to the ideal answer.\n",
        "\n",
        "* **Grammar Score :**  Using TextBlob’s correction feature, we estimate the grammatical correctness of the user’s answer. We compare the number of corrected words to the original to derive a grammar score.\n",
        "\n",
        "* **Final Score :** Combining the semantic similarity score and grammar score, we compute a final score to assess the overall quality of the user’s response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFUvdj1QGKrr"
      },
      "source": [
        "# Prepare the Dataset for AI Evaluation\n",
        "\n",
        "Before starting the interview simulation, the dataset containing the interview questions and their ideal answers needs to be properly prepared:\n",
        "\n",
        "* **Loading Data :**\n",
        "The questions and ideal answers are stored in a CSV file (interview_questions.csv). We load this file using Python’s csv.DictReader to read each question-answer pair into a list.\n",
        "\n",
        "* **Data Cleaning :**\n",
        "Although the dataset is assumed to be clean, any necessary preprocessing like trimming whitespace or handling missing values should be done here to avoid errors during evaluation.\n",
        "\n",
        "* **Organizing Questions :**\n",
        "We arrange the questions in a specific order presenting the first five questions in sequence, and then shuffling the rest to simulate a more dynamic interview experience.\n",
        "\n",
        "* **Encoding Answers :**\n",
        "The textual data will later be encoded into embeddings using a pre-trained sentence transformer model for semantic similarity evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9LnSiY-GgfT"
      },
      "source": [
        "#Implemented Baseline Scoring Model\n",
        "\n",
        "To evaluate the user's answers during the mock interview, a baseline scoring model was developed combining two key metrics:\n",
        "\n",
        "* **Semantic Similarity :**\n",
        "Using a pre-trained SentenceTransformer model (all-MiniLM-L6-v2), both the user’s answer and the ideal answer are converted into vector embeddings. The cosine similarity between these embeddings measures how closely the meanings match. The similarity score is scaled to a 0–10 range.\n",
        "\n",
        "* **Grammar Check :**\n",
        "Using TextBlob, the user’s answer undergoes a grammar check. The model estimates grammatical correctness by comparing the original text with the corrected text, assigning a grammar score also scaled from 0 to 10.\n",
        "\n",
        "* **Final Score :**\n",
        "The final score for each answer is calculated as the average of the semantic similarity score and the grammar score, providing a balanced evaluation of both content relevance and language correctness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjYV56FGG9k0"
      },
      "source": [
        "#Trained and Evaluated the AI Scoring Logic\n",
        "\n",
        "The AI scoring logic was developed and assessed using the dataset of interview questions and their ideal answers. Key steps included:\n",
        "\n",
        "* **Model Selection :**\n",
        "Utilized the all-MiniLM-L6-v2 SentenceTransformer model for generating semantic embeddings due to its efficiency and effectiveness in capturing contextual meaning.\n",
        "\n",
        "* **Evaluation Metrics :**\n",
        "The system scores user answers based on semantic similarity to the ideal answer and grammar correctness using TextBlob’s correction capabilities.\n",
        "\n",
        "* **Testing :**\n",
        "Conducted multiple rounds of mock interviews by inputting sample user answers to validate the scoring behavior, ensuring that the similarity and grammar scores accurately reflect answer quality.\n",
        "\n",
        "* **Performance Review :**\n",
        "The average final score over multiple questions provides an overall interview readiness measure, guiding users on whether their answers meet acceptable standards or require improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0KNMKjMIgkl"
      },
      "source": [
        "#Hyperparameter Tuning\n",
        "\n",
        "Hyperparameter tuning involves adjusting specific parameters that affect how the model or evaluation logic performs. Although this project uses pre-trained models, we refined various scoring-related parameters to improve the accuracy and fairness of the interview evaluation. This process ensures that the system provides balanced and meaningful feedback based on both content relevance and grammar quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuQhvqOcI7CL"
      },
      "source": [
        "# Final Version of AI Interview Bot\n",
        "\n",
        "In the final version, all components of the AI Mock Interview Bot were integrated into a complete and functional system. This version includes data handling, semantic similarity scoring, grammar evaluation, and a user-friendly interactive interface. The bot evaluates each response, provides scores, and offers constructive feedback, simulating a real interview experience. This finalized version is ready for demonstration, testing, and further enhancement based on future requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaXADvWLZUPF",
        "outputId": "76a8dd84-7aa4-4d0a-c2bd-079789d00bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Welcome to AI Mock Interview Bot!\n",
            "\n",
            "Q1: Tell me about yourself.\n",
            "Your Answer: I am Nikshay,B.Tech CSE(AI) studennt \n",
            " Similarity Score: 3.33/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 6.66/10\n",
            "\n",
            "Q2: What are your strengths?\n",
            "Your Answer: My strengths are strong problem solving skills\n",
            " Similarity Score: 3.78/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 6.89/10\n",
            "\n",
            "Q3: Why should we hire you?\n",
            "Your Answer: you should hire me because I am passionate about AI\n",
            " Similarity Score: 2.89/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 6.45/10\n",
            "\n",
            "Q4: Describe a challenging project you worked on.\n",
            "Your Answer: A challenging project I worked on was buliding an arudino based robot \n",
            " Similarity Score: 3.56/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 6.78/10\n",
            "\n",
            "Q5: What are your career goals?\n",
            "Your Answer: To became a AI engineer\n",
            " Similarity Score: 2.14/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 6.07/10\n",
            "\n",
            "Q6: What is a decision tree?\n",
            "Your Answer: A flowchart-like structure used for classification and regression.\n",
            " Similarity Score: 10.00/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 10.00/10\n",
            "\n",
            "Q7: What is reinforcement learning?\n",
            "Your Answer: An area of ML where agents learn to make decisions\n",
            " Similarity Score: 9.10/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 9.55/10\n",
            "\n",
            "Q8: Explain the concept of OOP.\n",
            "Your Answer: OOP includes encapsulation, inheritance\n",
            " Similarity Score: 6.34/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 8.17/10\n",
            "\n",
            "Q9: What is an API?\n",
            "Your Answer: An API is a set of protocols that allows different software applications to communicate.\n",
            " Similarity Score: 10.00/10\n",
            " Grammar Score: 10.00/10\n",
            " Final Score: 10.00/10\n",
            "\n",
            "Q10: What is the difference between AI and ML?\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "from textblob import TextBlob\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "questions = []\n",
        "with open('interview_questions.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        questions.append((row['question'], row['ideal_answer']))\n",
        "\n",
        "first_five = questions[:5]\n",
        "remaining = questions[5:]\n",
        "random.shuffle(remaining)\n",
        "final_questions = first_five + remaining\n",
        "\n",
        "print(\" Welcome to AI Mock Interview Bot!\\n\")\n",
        "\n",
        "total_score = 0\n",
        "\n",
        "for i, (question, ideal_answer) in enumerate(final_questions):\n",
        "    print(f\"Q{i+1}: {question}\")\n",
        "    user_answer = input(\"Your Answer: \")\n",
        "\n",
        "    embeddings = model.encode([user_answer, ideal_answer])\n",
        "    similarity_score = util.cos_sim(embeddings[0], embeddings[1]).item() * 10\n",
        "\n",
        "    blob = TextBlob(user_answer)\n",
        "    corrected = blob.correct()\n",
        "    grammar_score = max(0, 10 - len(corrected.words) + len(blob.words))\n",
        "\n",
        "    final_score = (similarity_score + grammar_score) / 2\n",
        "    total_score += final_score\n",
        "\n",
        "    print(f\" Similarity Score: {similarity_score:.2f}/10\")\n",
        "    print(f\" Grammar Score: {grammar_score:.2f}/10\")\n",
        "    print(f\" Final Score: {final_score:.2f}/10\\n\")\n",
        "\n",
        "average_score = total_score / len(final_questions)\n",
        "print(f\"Final Interview Score: {average_score:.2f}/10\")\n",
        "\n",
        "if average_score > 7:\n",
        "    print(\"Great job! You're interview-ready.\")\n",
        "else:\n",
        "    print(\" Needs improvement. Keep practicing and refining your answers.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "134d81lgJTWs"
      },
      "source": [
        "#Summary\n",
        "\n",
        "The AI Mock Interview Bot is an interactive system designed to help users prepare for job interviews. It leverages Natural Language Processing (NLP) to assess answers based on semantic similarity and grammar. The project involved structured steps including data preparation, feature analysis, model implementation, and evaluation. The final system provides real-time feedback and scoring, offering a valuable self-assessment tool for interview readiness. This project demonstrates how AI can support skill development and confidence-building in job seekers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVuiFPRPJiez"
      },
      "source": [
        "#Future Work Ideas\n",
        "\n",
        "* **Speech-to-Text Integration :**\n",
        "Allow users to speak their answers instead of typing, using voice recognition for a more realistic interview experience.\n",
        "\n",
        "* **Resume-Based Question Generation :**\n",
        "Dynamically generate interview questions based on the user's uploaded resume or profile to personalize the experience.\n",
        "\n",
        "* **Feedback Explanation :**\n",
        "Provide detailed insights into why an answer was good or how it can be improved (e.g., usage of soft skills, technical accuracy).\n",
        "\n",
        "* **Multi-language Support :**\n",
        "Enable the bot to understand and evaluate responses in multiple languages to increase global accessibility.\n",
        "\n",
        "* **Domain-Specific Interviews :**\n",
        "Customize interview questions and scoring logic for specific job domains like Data Science, Web Development, Marketing, etc.\n",
        "\n",
        "* **Interview Simulation Scoring History :**\n",
        "Track and visualize users' performance over time to highlight strengths and areas needing improvement.\n",
        "\n",
        "* **Integration with Chat Platforms :**\n",
        "Deploy the bot on platforms like Telegram, WhatsApp, or a website for easier access and real-time interaction."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
